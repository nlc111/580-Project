# -*- coding: utf-8 -*-
"""Phase 1 B Cost Schedule Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18G_-1UtZHq4O0_NAqCX1Re1-rKP9oSUf
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import os

"""
Phase 2: Cost Analysis and Credit Modeling 
Analyzes the relationship between schedule characteristics and costs
Uses statistical methods to understand cost drivers and credit calculations

"""

# ============================================================================
# CONFIGURATION
# ============================================================================

INPUT_FILE = "/content/sample_data/schedule_analysis_phase1.csv"  # Output from Phase 1
OUTPUT_DIR = "phase2_results"  # Directory for outputs

# Create output directory if it doesn't exist
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Set plot style for better-looking visualizations
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

# ============================================================================
# SECTION 1: DATA LOADING AND PREPARATION
# ============================================================================

def load_and_prepare_data(filename):
    """
    Load the Phase 1 results and prepare data for analysis
    Removes any rows with missing cost data 
    """
    print("=" * 70)
    print("LOADING DATA FROM PHASE 1")
    print("=" * 70)

    # Read the CSV file
    df = pd.read_csv(filename)
    print(f"âœ“ Loaded {len(df)} schedules from {filename}")

    # Remove rows with missing actual_cost (can't model cost without it)
    initial_rows = len(df)
    df = df.dropna(subset=['actual_cost'])
    removed = initial_rows - len(df)

    if removed > 0:
        print(f" Removed {removed} schedules with missing cost data")
    print(f"âœ“ Working with {len(df)} schedules with complete data\n")

    # Create derived features that might be useful for analysis

    # Cost per credited hour - a measure of efficiency
    df['cost_per_credit'] = df['actual_cost'] / df['actual_credits']

    # Working days (31 days - vacations)
    df['working_days'] = 31 - df['vacations']

    # Average flight time per duty
    df['flight_time_per_duty'] = df['flight_time_hours'] / df['num_duties']

    # The mysterious extra credits we discovered in Phase 1
    # This represents credits beyond flight time minus briefing
    # Likely includes per diem, layover credits, duty rigs, etc.
    df['extra_credits'] = df['credit_difference']  # Already calculated in Phase 1

    # Extra credits per duty - normalizes for schedule length
    df['extra_credits_per_duty'] = df['extra_credits'] / df['num_duties']

    print("âœ“ Created derived features:")
    print("  - cost_per_credit: Cost efficiency metric")
    print("  - working_days: Days not on vacation")
    print("  - flight_time_per_duty: Average flight time per duty")
    print("  - extra_credits: Credits beyond flight time - briefing")
    print("  - extra_credits_per_duty: Normalized extra credits\n")

    return df

# ============================================================================
# SECTION 2: EXPLORATORY DATA ANALYSIS (EDA)
# ============================================================================

def generate_summary_statistics(df):
    """
    Generate summary statistics for all numeric variables
    Helps understand the distribution and range of our data
    """
    print("=" * 70)
    print("SUMMARY STATISTICS")
    print("=" * 70)

    # Select numeric columns for summary
    numeric_cols = ['flight_time_hours', 'num_duties', 'briefing_hours',
                    'calculated_credits', 'actual_credits', 'actual_cost',
                    'vacations', 'credit_difference', 'cost_per_credit',
                    'working_days', 'extra_credits_per_duty']

    # Calculate summary stats
    summary_df = df[numeric_cols].describe().T
    summary_df = summary_df[['mean', '50%', 'std', 'min', 'max']]
    summary_df.columns = ['Mean', 'Median', 'Std_Dev', 'Min', 'Max']
    summary_df = summary_df.round(2)

    print(summary_df)

    # Save to CSV
    output_file = os.path.join(OUTPUT_DIR, "summary_statistics.csv")
    summary_df.to_csv(output_file)
    print(f"\nâœ“ Saved summary statistics to: {output_file}\n")

    return summary_df

def analyze_by_base(df):
    """
    Analyze costs and credits by base
    Different bases may have different cost structures or crew compositions
    """
    print("=" * 70)
    print("ANALYSIS BY BASE")
    print("=" * 70)

    by_base = df.groupby('base').agg({
        'schedule_num': 'count',
        'actual_cost': 'mean',
        'actual_credits': 'mean',
        'cost_per_credit': 'mean',
        'num_duties': 'mean',
        'vacations': 'mean',
        'extra_credits': 'mean'
    }).round(2)

    by_base.columns = ['count', 'mean_cost', 'mean_credits',
                       'mean_cost_per_credit', 'mean_duties',
                       'mean_vacations', 'mean_extra_credits']

    print(by_base)

    # Save to CSV
    output_file = os.path.join(OUTPUT_DIR, "analysis_by_base.csv")
    by_base.to_csv(output_file)
    print(f"\nâœ“ Saved base analysis to: {output_file}\n")

    return by_base

def calculate_correlations(df):
    """
    Calculate correlation matrix to understand relationships between variables
    Strong correlations (near Â±1) indicate variables that move together
    """
    print("=" * 70)
    print("CORRELATION ANALYSIS")
    print("=" * 70)

    # Select variables for correlation analysis
    vars_of_interest = ['actual_cost', 'actual_credits', 'num_duties',
                       'vacations', 'flight_time_hours', 'extra_credits',
                       'cost_per_credit', 'working_days']

    # Create correlation matrix
    cor_matrix = df[vars_of_interest].corr()

    # Print correlations with actual_cost (our target variable)
    print("Correlations with actual_cost:")
    print("-" * 70)
    cost_corr = cor_matrix['actual_cost'].drop('actual_cost').sort_values(ascending=False)
    for var, corr in cost_corr.items():
        print(f"  {var:25} : {corr:.3f}")

    # Save full correlation matrix
    output_file = os.path.join(OUTPUT_DIR, "correlation_matrix.csv")
    cor_matrix.to_csv(output_file)
    print(f"\n Saved correlation matrix to: {output_file}\n")

    return cor_matrix

# ============================================================================
# SECTION 3: VISUALIZATION
# ============================================================================

def plot_cost_vs_credits(df):
    """
    Create scatter plot: Cost vs. Actual Credits
    Shows if there's a linear relationship between credits and cost
    """
    print("Creating plot: Cost vs. Actual Credits...")

    plt.figure(figsize=(10, 6))

    # Scatter plot by base with different colors
    for base in df['base'].unique():
        base_data = df[df['base'] == base]
        plt.scatter(base_data['actual_credits'], base_data['actual_cost'],
                   label=base, alpha=0.6, s=80)

    # Add overall trend line
    z = np.polyfit(df['actual_credits'], df['actual_cost'], 1)
    p = np.poly1d(z)
    x_line = np.linspace(df['actual_credits'].min(), df['actual_credits'].max(), 100)
    plt.plot(x_line, p(x_line), 'k--', linewidth=2, label='Trend Line')

    plt.xlabel('Actual Credits (hours)', fontsize=12)
    plt.ylabel('Cost ($)', fontsize=12)
    plt.title('Schedule Cost vs. Actual Credits', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    output_file = os.path.join(OUTPUT_DIR, "cost_vs_credits.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ Saved: {output_file}\n")

def plot_cost_vs_duties(df):
    """
    Create scatter plot: Cost vs. Duties
    Examines if number of duties (flying days) affects cost
    """
    print("Creating plot: Cost vs. Duties...")

    plt.figure(figsize=(10, 6))

    for base in df['base'].unique():
        base_data = df[df['base'] == base]
        plt.scatter(base_data['num_duties'], base_data['actual_cost'],
                   label=base, alpha=0.6, s=80)

    plt.xlabel('Number of Duties', fontsize=12)
    plt.ylabel('Cost ($)', fontsize=12)
    plt.title('Schedule Cost vs. Number of Duties', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    output_file = os.path.join(OUTPUT_DIR, "cost_vs_duties.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ Saved: {output_file}\n")

def plot_cost_per_credit_by_base(df):
    """
    Create box plot: Cost per Credit by Base
    Shows the distribution and variability of cost efficiency across bases
    """
    print("Creating plot: Cost per Credit by Base...")

    plt.figure(figsize=(10, 6))

    bases = df['base'].unique()
    data_to_plot = [df[df['base'] == base]['cost_per_credit'].values for base in bases]

    plt.boxplot(data_to_plot, labels=bases)
    plt.xlabel('Base', fontsize=12)
    plt.ylabel('Cost per Credit ($/hour)', fontsize=12)
    plt.title('Cost per Credit Hour by Base', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3, axis='y')
    plt.tight_layout()

    output_file = os.path.join(OUTPUT_DIR, "cost_per_credit_by_base.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ Saved: {output_file}\n")

def plot_extra_credits_distribution(df):
    """
    Create histogram: Distribution of Extra Credits
    Shows how the mysterious "extra credits" are distributed
    Helps us understand what's typical vs. unusual
    """
    print("Creating plot: Extra Credits Distribution...")

    plt.figure(figsize=(10, 6))

    plt.hist(df['extra_credits'], bins=15, color='steelblue', edgecolor='black', alpha=0.7)
    plt.axvline(df['extra_credits'].mean(), color='red', linestyle='--',
                linewidth=2, label=f'Mean: {df["extra_credits"].mean():.2f}')

    plt.xlabel('Extra Credits (hours)', fontsize=12)
    plt.ylabel('Frequency', fontsize=12)
    plt.title('Distribution of Extra Credits\n(Credits beyond Flight Time - Briefing)',
              fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3, axis='y')
    plt.tight_layout()

    output_file = os.path.join(OUTPUT_DIR, "extra_credits_distribution.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ Saved: {output_file}\n")

# ============================================================================
# SECTION 4: REGRESSION MODELING
# ============================================================================

def build_model(df, features, target='actual_cost', model_name="Model"):
    """
    Generic function to build and evaluate a linear regression model

    Parameters:
    - df: DataFrame with the data
    - features: list of feature column names
    - target: target variable column name
    - model_name: name for display purposes

    Returns: model, predictions, residuals, metrics
    """
    # Prepare data
    X = df[features].values
    y = df[target].values

    # Fit model
    model = LinearRegression()
    model.fit(X, y)

    # Make predictions
    predictions = model.predict(X)
    residuals = y - predictions

    # Calculate metrics
    r2 = r2_score(y, predictions)
    adj_r2 = 1 - (1 - r2) * (len(y) - 1) / (len(y) - len(features) - 1)
    rmse = np.sqrt(mean_squared_error(y, predictions))
    mae = mean_absolute_error(y, predictions)

    metrics = {
        'r2': r2,
        'adj_r2': adj_r2,
        'rmse': rmse,
        'mae': mae,
        'n_params': len(features) + 1  # +1 for intercept
    }

    return model, predictions, residuals, metrics

def build_model_1(df):
    """
    Model 1: Simple Linear Regression - Cost predicted by Credits 
     Cost = beta_0 + beta_1 Ã— actual_credits

    Tests hypothesis: Cost is primarily driven by credited hours
    """
    print("=" * 70)
    print("MODEL 1: Cost ~ Actual Credits")
    print("=" * 70)
    print("Hypothesis: Cost is linearly proportional to credited hours")
    print("-" * 70)

    features = ['actual_credits']
    model, predictions, residuals, metrics = build_model(df, features, model_name="Model 1")

    print(f"\nModel Performance:")
    print(f"  RÂ² (variance explained):     {metrics['r2']:.4f}")
    print(f"  Adjusted R^2:                 {metrics['adj_r2']:.4f}")
    print(f"  RMSE (prediction error):     ${metrics['rmse']:.2f}")
    print(f"  Mean Absolute Error:         ${metrics['mae']:.2f}")

    print(f"\nInterpretation:")
    print(f"  Base cost (intercept):       ${model.intercept_:.2f}")
    print(f"  Cost per credit hour:        ${model.coef_[0]:.2f}")
    print(f"\n  â†’ Each additional credit hour adds ~${model.coef_[0]:.2f} to cost\n")

    return model, predictions, residuals, metrics

def build_model_2(df):
    """
    Model 2: Multiple Linear Regression - Cost predicted by Credits, Duties, and Vacations
    Cost = Î²â‚€ + Î²â‚Ã—credits + Î²â‚‚Ã—duties + Î²â‚ƒÃ—vacations

    Tests if duties and vacation days add explanatory power beyond just credits
    """
    print("=" * 70)
    print("MODEL 2: Cost ~ Actual Credits + Duties + Vacations")
    print("=" * 70)
    print("Hypothesis: Cost depends on credits, number of duties, and vacation days")
    print("-" * 70)

    features = ['actual_credits', 'num_duties', 'vacations']
    model, predictions, residuals, metrics = build_model(df, features, model_name="Model 2")

    print(f"\nModel Performance:")
    print(f"  RÂ² (variance explained):     {metrics['r2']:.4f}")
    print(f"  Adjusted RÂ²:                 {metrics['adj_r2']:.4f}")
    print(f"  RMSE (prediction error):     ${metrics['rmse']:.2f}")
    print(f"  Mean Absolute Error:         ${metrics['mae']:.2f}")

    print(f"\nInterpretation:")
    print(f"  Base cost:                   ${model.intercept_:.2f}")
    print(f"  Effect of 1 credit hour:     ${model.coef_[0]:.2f}")
    print(f"  Effect of 1 duty:            ${model.coef_[1]:.2f}")
    print(f"  Effect of 1 vacation day:    ${model.coef_[2]:.2f}\n")

    return model, predictions, residuals, metrics

def build_model_3(df):
    """
    Model 3: Multiple Regression with Base as Dummy Variables
    Cost = Î²â‚€ + Î²â‚Ã—credits + Î²â‚‚Ã—duties + Î²â‚ƒÃ—vacations + Î²â‚„Ã—(BASE2) + Î²â‚…Ã—(BASE3)

    Tests if different bases have systematically different costs
    BASE1 is the reference category (absorbed into intercept)
    """
    print("=" * 70)
    print("MODEL 3: Cost ~ Actual Credits + Duties + Vacations + Base")
    print("=" * 70)
    print("Hypothesis: Different bases have different cost structures")
    print("-" * 70)

    # Create dummy variables for base (BASE1 is reference)
    df_model = df.copy()
    df_model['base_BASE2'] = (df_model['base'] == 'BASE2').astype(int)
    df_model['base_BASE3'] = (df_model['base'] == 'BASE3').astype(int)

    features = ['actual_credits', 'num_duties', 'vacations', 'base_BASE2', 'base_BASE3']
    model, predictions, residuals, metrics = build_model(df_model, features, model_name="Model 3")

    print(f"\nModel Performance:")
    print(f"  RÂ² (variance explained):     {metrics['r2']:.4f}")
    print(f"  Adjusted RÂ²:                 {metrics['adj_r2']:.4f}")
    print(f"  RMSE (prediction error):     ${metrics['rmse']:.2f}")
    print(f"  Mean Absolute Error:         ${metrics['mae']:.2f}")

    print(f"\nInterpretation:")
    print(f"  Base cost (BASE1):           ${model.intercept_:.2f}")
    print(f"  Effect of 1 credit hour:     ${model.coef_[0]:.2f}")
    print(f"  Effect of 1 duty:            ${model.coef_[1]:.2f}")
    print(f"  Effect of 1 vacation day:    ${model.coef_[2]:.2f}")
    print(f"  BASE2 vs BASE1 difference:   ${model.coef_[3]:.2f}")
    print(f"  BASE3 vs BASE1 difference:   ${model.coef_[4]:.2f}")
    print("\nNote: BASE1 is the reference category (in the intercept)")
    print("      Coefficients for BASE2 and BASE3 show difference from BASE1\n")

    return model, predictions, residuals, metrics

def build_model_4(df):
    """
    Model 4: Full Model with Interaction Terms
    Cost = Î²â‚€ + Î²â‚Ã—credits + Î²â‚‚Ã—duties + Î²â‚ƒÃ—vacations + Î²â‚„Ã—(credits Ã— duties)

    Tests if the effect of credits depends on number of duties (interaction effect)
    For example: Does an extra credit hour cost more on schedules with many duties?
    """
    print("=" * 70)
    print("MODEL 4: Cost ~ Credits + Duties + Vacations + (Credits Ã— Duties)")
    print("=" * 70)
    print("Hypothesis: The effect of credits on cost depends on number of duties")
    print("-" * 70)

    # Create interaction term
    df_model = df.copy()
    df_model['credits_duties_interaction'] = df_model['actual_credits'] * df_model['num_duties']

    features = ['actual_credits', 'num_duties', 'vacations', 'credits_duties_interaction']
    model, predictions, residuals, metrics = build_model(df_model, features, model_name="Model 4")

    print(f"\nModel Performance:")
    print(f"  RÂ² (variance explained):     {metrics['r2']:.4f}")
    print(f"  Adjusted RÂ²:                 {metrics['adj_r2']:.4f}")
    print(f"  RMSE (prediction error):     ${metrics['rmse']:.2f}")
    print(f"  Mean Absolute Error:         ${metrics['mae']:.2f}\n")

    return model, predictions, residuals, metrics

def compare_models(models_info):
    """
    Compare all models side-by-side
    Shows which model explains cost best and whether added complexity helps
    """
    print("=" * 70)
    print("MODEL COMPARISON")
    print("=" * 70)

    comparison_data = []
    for name, _, _, _, metrics in models_info:
        comparison_data.append({
            'Model': name,
            'R_Squared': round(metrics['r2'], 4),
            'Adj_R_Squared': round(metrics['adj_r2'], 4),
            'RMSE': round(metrics['rmse'], 2),
            'Num_Parameters': metrics['n_params']
        })

    comparison_df = pd.DataFrame(comparison_data)
    print(comparison_df.to_string(index=False))

    print("\nInterpretation Guide:")
    print("  RÂ²: Proportion of variance explained (higher is better, 0-1 scale)")
    print("  Adj RÂ²: RÂ² adjusted for number of parameters (penalizes complexity)")
    print("  RMSE: Average prediction error in dollars (lower is better)")
    print("  Num_Parameters: Number of coefficients in the model")
    print("\n  â†’ Look for high RÂ² with low RMSE")
    print("  â†’ Adjusted RÂ² helps compare models with different complexity\n")

    # Save comparison
    output_file = os.path.join(OUTPUT_DIR, "model_comparison.csv")
    comparison_df.to_csv(output_file, index=False)
    print(f"âœ“ Saved model comparison to: {output_file}\n")

    return comparison_df

# ============================================================================
# SECTION 5: RESIDUAL ANALYSIS
# ============================================================================

def plot_predicted_vs_actual(df, predictions, model_name):
    """
    Plot predicted vs. actual costs for best model
    Good models should have points close to the diagonal line
    Points far from the line are prediction errors (residuals)
    """
    print(f"Creating plot: Predicted vs. Actual Costs ({model_name})...")

    plt.figure(figsize=(10, 6))

    plt.scatter(predictions, df['actual_cost'], alpha=0.6, s=80)

    # Add diagonal line (perfect prediction)
    min_val = min(predictions.min(), df['actual_cost'].min())
    max_val = max(predictions.max(), df['actual_cost'].max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')

    # Calculate and display RÂ²
    r2 = r2_score(df['actual_cost'], predictions)
    plt.text(0.05, 0.95, f'RÂ² = {r2:.3f}', transform=plt.gca().transAxes,
             fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.xlabel('Predicted Cost ($)', fontsize=12)
    plt.ylabel('Actual Cost ($)', fontsize=12)
    plt.title(f'Predicted vs. Actual Cost\n{model_name}', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    output_file = os.path.join(OUTPUT_DIR, f"predicted_vs_actual_{model_name.replace(' ', '_')}.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ Saved: {output_file}\n")

def plot_residuals(predictions, residuals, model_name):
    """
    Plot residuals (prediction errors) vs. predicted values
    Good models have randomly scattered residuals around zero
    Patterns in residuals indicate the model is missing something
    """
    print(f"Creating plot: Residual Analysis ({model_name})...")

    plt.figure(figsize=(10, 6))

    plt.scatter(predictions, residuals, alpha=0.6, s=80)
    plt.axhline(y=0, color='r', linestyle='--', linewidth=2, label='Zero Line')

    plt.xlabel('Predicted Cost ($)', fontsize=12)
    plt.ylabel('Residuals ($)', fontsize=12)
    plt.title(f'Residual Plot\n{model_name}', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    output_file = os.path.join(OUTPUT_DIR, f"residuals_{model_name.replace(' ', '_')}.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ Saved: {output_file}\n")

def identify_outliers(df, residuals, threshold=1000.0):
    """
    Identify outliers - schedules with large prediction errors
    These are interesting cases that don't fit the typical pattern
    """
    print("=" * 70)
    print("OUTLIER ANALYSIS")
    print("=" * 70)
    print(f"Identifying schedules with prediction errors > ${threshold}")
    print("-" * 70)

    # Add residuals to dataframe
    df_with_residuals = df.copy()
    df_with_residuals['residual'] = residuals
    df_with_residuals['abs_residual'] = np.abs(residuals)

    # Find outliers
    outliers = df_with_residuals[df_with_residuals['abs_residual'] > threshold]
    outliers = outliers.sort_values('abs_residual', ascending=False)

    if len(outliers) > 0:
        print(f"Found {len(outliers)} outliers:\n")

        # Display key info about outliers
        outlier_cols = ['schedule_num', 'employee', 'base', 'actual_cost',
                       'actual_credits', 'num_duties', 'residual']
        print(outliers[outlier_cols].to_string(index=False))

        # Save outliers
        output_file = os.path.join(OUTPUT_DIR, "outliers.csv")
        outliers.to_csv(output_file, index=False)
        print(f"\nâœ“ Saved outlier details to: {output_file}")
    else:
        print(f"No significant outliers found (all residuals < ${threshold})")
    print()

    return outliers

# ============================================================================
# SECTION 6: EXTRA CREDITS ANALYSIS
# ============================================================================

def analyze_extra_credits(df):
    """
    Analyze the mysterious "extra credits" (credit_difference from Phase 1)
    Try to understand what creates these additional credits beyond flight time
    """
    print("=" * 70)
    print("EXTRA CREDITS ANALYSIS")
    print("=" * 70)
    print(f"Investigating the {df['extra_credits'].mean():.2f} hour average gap")
    print("between actual credits and (flight time - briefing)")
    print("-" * 70)

    # Model: Can we predict extra credits from schedule characteristics?
    features = ['num_duties', 'vacations', 'working_days']
    model, predictions, residuals, metrics = build_model(df, features,
                                                        target='extra_credits',
                                                        model_name="Extra Credits Model")

    print(f"\nRÂ² = {metrics['r2']:.4f}")
    print(f"\nInterpretation:")
    print(f"  Base extra credits:          {model.intercept_:.2f} hours")
    print(f"  Per duty:                    {model.coef_[0]:.2f} hours")
    print(f"  Per vacation day:            {model.coef_[1]:.2f} hours")
    print(f"  Per working day:             {model.coef_[2]:.2f} hours")

    print("\nğŸ’¡ Insight: Extra credits likely include:")
    print("   - Per diem credits for days away from base")
    print("   - Duty rig guarantees (minimum credit per duty)")
    print("   - Layover credits")
    print("   - Positioning/deadhead credits")

    # Calculate extra credits per duty by base
    print("\nExtra Credits per Duty by Base:")
    by_base_extra = df.groupby('base')['extra_credits_per_duty'].agg(['mean', 'std']).round(2)
    by_base_extra.columns = ['mean_extra_per_duty', 'std_extra_per_duty']
    print(by_base_extra)
    print()

    return model, metrics

# ============================================================================
# SECTION 7: FINAL REPORT GENERATION
# ============================================================================

def generate_final_report(df, models_info, comparison_df):
    """
    Generate a comprehensive final report summarizing all findings
    """
    print("=" * 70)
    print("GENERATING FINAL REPORT")
    print("=" * 70)

    report_file = os.path.join(OUTPUT_DIR, "phase2_final_report.txt")

    with open(report_file, 'w') as f:
        f.write("=" * 70 + "\n")
        f.write("CREW SCHEDULE COST ANALYSIS - PHASE 2 FINAL REPORT\n")
        f.write("=" * 70 + "\n\n")

        f.write("EXECUTIVE SUMMARY\n")
        f.write("-" * 70 + "\n")
        f.write(f"Analyzed {len(df)} crew schedules to understand cost drivers\n\n")

        f.write("KEY FINDINGS:\n\n")

        # Best model
        best_model_idx = comparison_df['Adj_R_Squared'].idxmax()
        best_model_name = comparison_df.loc[best_model_idx, 'Model']
        best_r2 = comparison_df.loc[best_model_idx, 'R_Squared']
        best_rmse = comparison_df.loc[best_model_idx, 'RMSE']

        f.write(f"1. BEST PREDICTIVE MODEL: {best_model_name}\n")
        f.write(f"   - Explains {best_r2*100:.1f}% of cost variation\n")
        f.write(f"   - Average prediction error: ${best_rmse:.2f}\n\n")

        # Cost structure
        avg_cost = df['actual_cost'].mean()
        avg_credits = df['actual_credits'].mean()
        avg_cost_per_credit = df['cost_per_credit'].mean()

        f.write("2. COST STRUCTURE:\n")
        f.write(f"   - Average schedule cost: ${avg_cost:.2f}\n")
        f.write(f"   - Average credits: {avg_credits:.2f} hours\n")
        f.write(f"   - Average cost per credit: ${avg_cost_per_credit:.2f}/hour\n\n")

        # Extra credits insight
        avg_extra = df['extra_credits'].mean()
        f.write("3. CREDIT CALCULATION:\n")
        f.write(f"   - Average extra credits: {avg_extra:.2f} hours\n")
        f.write("   - These represent credits beyond flight time minus briefing\n")
        f.write("   - Likely include: per diem, duty rigs, layover credits\n\n")

        # Base differences
        f.write("4. BASE DIFFERENCES:\n")
        by_base = df.groupby('base')['cost_per_credit'].mean()
        for base, cost in by_base.items():
            f.write(f"   - {base}: ${cost:.2f}/hour\n")

        f.write("\n" + "=" * 70 + "\n")
        f.write("END OF REPORT\n")
        f.write("=" * 70 + "\n")

    print(f"âœ“ Final report saved to: {report_file}\n")

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """
    Main execution function that runs all analyses
    """
    # Load and prepare data
    df = load_and_prepare_data(INPUT_FILE)

    # Exploratory analysis
    summary_stats = generate_summary_statistics(df)
    base_analysis = analyze_by_base(df)
    cor_matrix = calculate_correlations(df)

    # Create visualizations
    plot_cost_vs_credits(df)
    plot_cost_vs_duties(df)
    plot_cost_per_credit_by_base(df)
    plot_extra_credits_distribution(df)

    # Build regression models
    model1, pred1, resid1, metrics1 = build_model_1(df)
    model2, pred2, resid2, metrics2 = build_model_2(df)
    model3, pred3, resid3, metrics3 = build_model_3(df)
    model4, pred4, resid4, metrics4 = build_model_4(df)

    # Compare models
    models_info = [
        ("Model 1: Credits Only", model1, pred1, resid1, metrics1),
        ("Model 2: Credits + Duties + Vacations", model2, pred2, resid2, metrics2),
        ("Model 3: + Base Effects", model3, pred3, resid3, metrics3),
        ("Model 4: + Interactions", model4, pred4, resid4, metrics4)
    ]
    comparison = compare_models(models_info)

    # Residual analysis for best model (typically model 2 or 3)
    plot_predicted_vs_actual(df, pred2, "Model 2")
    plot_residuals(pred2, resid2, "Model 2")
    outliers = identify_outliers(df, resid2, threshold=1000.0)

    # Extra credits analysis
    extra_model, extra_metrics = analyze_extra_credits(df)

    # Generate final report
    generate_final_report(df, models_info, comparison)

    print("=" * 70)
    print("PHASE 2 ANALYSIS COMPLETE!")
    print("=" * 70)
    print(f"All results saved to: {OUTPUT_DIR}/")
    print("=" * 70)

    return df, models_info, comparison

# Run the analysis
if __name__ == "__main__":
    df, models_info, comparison = main()
